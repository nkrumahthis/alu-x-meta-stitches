{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPaeal2NW65e/nJSn+3ya5f",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/nkrumahthis/alu-x-meta-stitches/blob/main/stitches.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "! pip3 install --upgrade --quiet google-cloud-aiplatform openai google"
      ],
      "metadata": {
        "id": "MzVQNDm35Icg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import openai\n",
        "\n",
        "from google.auth import default, transport\n",
        "from google.cloud import storage\n",
        "\n",
        "from google.oauth2 import service_account\n",
        "from google.colab import auth\n",
        "\n",
        "from PIL import Image\n",
        "import requests\n",
        "\n",
        "import io\n",
        "from IPython.display import display\n",
        "\n",
        "import base64\n",
        "\n",
        "import re\n",
        "import json\n",
        "\n",
        "# path to google oauth2 JSON key file\n",
        "KEY_FILE_PATH = './cred.json'\n",
        "\n",
        "# Load credentials from the JSON key file\n",
        "credentials = service_account.Credentials.from_service_account_file(\n",
        "    KEY_FILE_PATH,\n",
        "    scopes=['https://www.googleapis.com/auth/cloud-platform']\n",
        ")\n",
        "\n",
        "# Authenticate using the service account credentials\n",
        "auth.authenticate_user()\n",
        "\n",
        "credentials, _ = default()\n",
        "auth_request = transport.requests.Request()\n",
        "credentials.refresh(auth_request)\n",
        "\n",
        "LOCATION = \"us-central1\"\n",
        "MAAS_ENDPOINT = f\"{LOCATION}-aiplatform.googleapis.com\"\n",
        "PROJECT_ID=\"studious-plate-436913-c1\"\n",
        "MODEL_ID=\"meta/llama-3.2-90b-vision-instruct-maas\"\n",
        "BUCKET_URI = \"gs://metallama3bootcamp\""
      ],
      "metadata": {
        "id": "6VNF8nyD5DiU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "openai_client = openai.OpenAI(\n",
        "        base_url=f\"https://{MAAS_ENDPOINT}/v1beta1/projects/{PROJECT_ID}/locations/{LOCATION}/endpoints/openapi\",\n",
        "        api_key=credentials.token,\n",
        "    )\n",
        "\n",
        "bucket_name = \"metallama3bootcamp\"\n",
        "\n",
        "storage_client = storage.Client()\n",
        "\n",
        "# Get the bucket\n",
        "bucket = storage_client.bucket(bucket_name)\n"
      ],
      "metadata": {
        "id": "XM6QpOfT5kJ8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "blobs = bucket.list_blobs()\n",
        "# Create a list of blob names\n",
        "blob_names = [blob.name for blob in blobs]\n",
        "\n",
        "image_names = [name for name in blob_names if name.endswith('.png')]\n",
        "image_names.sort()\n",
        "\n",
        "# print(blob_names)\n",
        "print(image_names)"
      ],
      "metadata": {
        "id": "8PZF-SZK5x7j"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "river_date_list = []\n",
        "\n",
        "rivers = {}\n",
        "\n",
        "for image_name in image_names:\n",
        "    match = re.match(r'^(.+?)_(\\d{4}-\\d{2}-\\d{2})\\.png$', image_name)\n",
        "    if match:\n",
        "        river_name = match.group(1)\n",
        "        date = match.group(2)\n",
        "        river_date_list.append({\"name\": river_name, \"date\": date, \"file\": image_name})\n",
        "\n",
        "        if river_name not in rivers:\n",
        "            rivers[river_name] = []\n",
        "        rivers[river_name].append({\"name\": river_name, \"date\": date, \"file\": image_name})\n",
        "\n",
        "\n",
        "print(rivers)\n"
      ],
      "metadata": {
        "id": "FXS-O2xC6VhT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2IfvO8R_41ou"
      },
      "outputs": [],
      "source": [
        "def stitch_images(images):\n",
        "  widths, heights = zip(*(i.size for i in images))\n",
        "\n",
        "  total_width = sum(widths)\n",
        "  max_height = max(heights)\n",
        "\n",
        "  new_im = Image.new('RGB', (total_width, max_height))\n",
        "\n",
        "  x_offset = 0\n",
        "  for im in images:\n",
        "    new_im.paste(im, (x_offset, 0))\n",
        "    x_offset += im.size[0]\n",
        "\n",
        "  return new_im"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## pass the stitched images and prompts into openai_client\n",
        "\n",
        "def query(stitched_image, prompt):\n",
        "  buffered = io.BytesIO()\n",
        "  stitched_image.save(buffered, format=\"PNG\")\n",
        "  img_str = base64.b64encode(buffered.getvalue()).decode()\n",
        "  river_image_url = f\"data:image/png;base64,{img_str}\"\n",
        "\n",
        "  max_tokens = 200\n",
        "\n",
        "  response = openai_client.chat.completions.create(\n",
        "        model=MODEL_ID,\n",
        "        messages=[\n",
        "            {\n",
        "                \"role\": \"user\",\n",
        "                \"content\": [\n",
        "                    {\n",
        "                        \"image_url\": {\n",
        "                            \"url\": river_image_url\n",
        "                        },\n",
        "                        \"type\": \"image_url\",\n",
        "                    },\n",
        "                    {\"text\": prompt, \"type\": \"text\"},\n",
        "                ],\n",
        "            },\n",
        "        ],\n",
        "        max_tokens=max_tokens,\n",
        "    )\n",
        "\n",
        "  print(response.choices[0].message.content)\n",
        "\n",
        "\n",
        "def pollution_score_query(stitched_image):\n",
        "  prompt = 'you are a pollution sensor. compare the parts of the stitched images and give a pollution value as a json like ```[{\"pollution\":1, \"year\": \"2020-09-11\"}, {\"pollution\":3, \"year\": \"2020-09-11\"}] pollution score is ```'\n",
        "  buffered = io.BytesIO()\n",
        "  stitched_image.save(buffered, format=\"PNG\")\n",
        "  img_str = base64.b64encode(buffered.getvalue()).decode()\n",
        "  river_image_url = f\"data:image/png;base64,{img_str}\"\n",
        "\n",
        "  max_tokens = 200\n",
        "\n",
        "  response = openai_client.chat.completions.create(\n",
        "        model=MODEL_ID,\n",
        "        messages=[\n",
        "            {\n",
        "                \"role\": \"user\",\n",
        "                \"content\": [\n",
        "                    {\n",
        "                        \"image_url\": {\n",
        "                            \"url\": river_image_url\n",
        "                        },\n",
        "                        \"type\": \"image_url\",\n",
        "                    },\n",
        "                    {\"text\": prompt, \"type\": \"text\"},\n",
        "                ],\n",
        "            },\n",
        "        ],\n",
        "        max_tokens=max_tokens,\n",
        "    )\n",
        "\n",
        "  print(response.choices[0].message.content)\n"
      ],
      "metadata": {
        "id": "sj0_8nicDKfn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for river in rivers.keys():\n",
        "  filenames = [image['file'] for image in rivers[river]]\n",
        "  filenames.sort()\n",
        "  dates = [image['date'] for image in rivers[river]]\n",
        "  dates.sort()\n",
        "\n",
        "  images = []\n",
        "\n",
        "  for filename in filenames:\n",
        "    blob_name = filename\n",
        "    blob = bucket.blob(blob_name)\n",
        "    image_data = blob.download_as_bytes()\n",
        "    image = Image.open(io.BytesIO(image_data))\n",
        "    images.append(image)\n",
        "\n",
        "  if len(images) < 2:\n",
        "    continue\n",
        "\n",
        "  stitched_image = stitch_images(images)\n",
        "  prompt = (\"\"\"\n",
        "    You are an environmentallist and a reporter.\n",
        "    This is a stitch of satellite images of the same river %s over the years with dates %s.\n",
        "    Give an analysis of the pollution and what the changes in the river are.\n",
        "    \"\"\") % (river, \", \".join(dates))\n",
        "\n",
        "  print(\"-\"*500)\n",
        "  print(river)\n",
        "  # print(\"-\"*500)\n",
        "  display(stitched_image)\n",
        "  query(stitched_image, prompt)\n",
        "  print(\"=\"*500)\n",
        "  print(\"\\n\\n\\n\")\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "y0u-SOT88J_T"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}